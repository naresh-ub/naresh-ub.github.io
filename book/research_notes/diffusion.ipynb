{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47baddb1",
   "metadata": {},
   "source": [
    "# Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0225d194-546b-4c72-9392-5a60152be0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n"
     ]
    }
   ],
   "source": [
    "print(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5c593",
   "metadata": {
    "tags": [
     "thebe-remove-input-init"
    ]
   },
   "outputs": [],
   "source": [
    "import micropip\n",
    "await micropip.install([\"ipympl\", 'scikit-image', 'scipy', 'ipywidgets'])\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from skimage.data import astronaut\n",
    "\n",
    "def update_blur(kernel_size):\n",
    "    blurred_image = apply_convolution(original_image, kernel_size)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_image.astype(np.uint8))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(blurred_image)\n",
    "    plt.title(f\"Blurred Image (Kernel: {kernel_size}x{kernel_size})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "# Required packages are already imported\n",
    "original_image = astronaut().astype(np.float32)\n",
    "\n",
    "def convolve2d_custom(image, kernel):\n",
    "    h, w = image.shape\n",
    "    k, _ = kernel.shape\n",
    "    pad = k // 2\n",
    "    padded_image = np.pad(image, pad, mode='edge')\n",
    "    strided_shape = (h, w, k, k)\n",
    "    strided_steps = padded_image.strides + padded_image.strides\n",
    "    image_windows = as_strided(padded_image, shape=strided_shape, strides=strided_steps)\n",
    "    return np.tensordot(image_windows, kernel, axes=([2, 3], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6607f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something\n"
     ]
    }
   ],
   "source": [
    "print(\"Someasfthing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca9ffa-ef07-44a4-b742-09bd0df6b2bc",
   "metadata": {},
   "source": [
    "# Understanding Diffusion from scratch\n",
    "\n",
    "```{warning}\n",
    "This notes is a work in progress, the content is not organized yet, only the content is dumped. Once entire content is complete, I will work on organizing the web page for readability.\n",
    "```\n",
    "\n",
    "There are two parts to this tutorial. The first part uses the [Step-by-Step Diffusion](https://arxiv.org/pdf/2406.08929v1) tutorial for strong foundations on the topic, the second part uses the [Stanley Chan's Tutorial on Diffusion ModelsTutorial on Diffusion Models](https://arxiv.org/pdf/2403.18103) for clear intuition on Stochastic Differential Equation formulation in diffusion models.\n",
    "\n",
    "## Fundamentals\n",
    "\n",
    "Each fundamental is clearly explained. The content for fundamentals is intentionally verbose.\n",
    "\n",
    "```{admonition} What is a random variable?\n",
    ":class: note, dropdown\n",
    "\n",
    "A **random variable** is a way to assign numbers to the outcomes of a random process.\n",
    "\n",
    "**Think of it like this:**  \n",
    "- You roll a die. The result (1, 2, 3, 4, 5, or 6) is a **random number** → This is a **random variable**.  \n",
    "- You measure the time it takes for a website to load. The time is **random and can take any real value** → Another **random variable**.  \n",
    "\n",
    "---\n",
    "\n",
    "**Types of Random Variables**  \n",
    "\n",
    "**1. Discrete Random Variable**  \n",
    "A discrete random variable can take only specific values (like whole numbers).  \n",
    "\n",
    "**Example: Rolling a Fair Die**  \n",
    "Let $ X $ be the number shown on a fair six-sided die. The possible values of $ X $ are:  \n",
    "\n",
    "$$\n",
    "X \\in \\{1, 2, 3, 4, 5, 6\\}\n",
    "$$\n",
    "\n",
    "Since the die is fair, each outcome has an equal probability:\n",
    "\n",
    "$$\n",
    "P(X = x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{6}, & x = 1,2,3,4,5,6 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For example, the probability of rolling a **4** is:\n",
    "\n",
    "$$\n",
    "P(X = 4) = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**2. Continuous Random Variable**  \n",
    "A continuous random variable can take **any value within a range**.  \n",
    "\n",
    "**Example: Webpage Loading Time**  \n",
    "Let $ Y $ be the time (in seconds) for a webpage to load. The possible values of $ Y $ are:  \n",
    "\n",
    "$$\n",
    "Y \\in [0, \\infty)\n",
    "$$\n",
    "\n",
    "Since $ Y $ can take infinitely many values, we use a **probability density function (PDF)** instead of exact probabilities.  \n",
    "\n",
    "If $ Y $ follows an **exponential distribution**, its PDF is:\n",
    "\n",
    "$$\n",
    "f_Y(y) = \\lambda e^{-\\lambda y}, \\quad y \\geq 0\n",
    "$$\n",
    "\n",
    "where $ \\lambda $ is a constant that controls the rate of decay.  \n",
    "\n",
    "To find the probability that the webpage loads in **less than 3 seconds**, we integrate the PDF:\n",
    "\n",
    "$$\n",
    "P(Y \\leq 3) = \\int_0^3 \\lambda e^{-\\lambda y} dy\n",
    "$$\n",
    "\n",
    "This gives the probability that the page loads within 3 seconds.  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- **Discrete Random Variable** → Takes countable values (e.g., die rolls, number of heads in coin flips).  \n",
    "- **Continuous Random Variable** → Takes any value in a range (e.g., time, temperature, height). \n",
    "```\n",
    "\n",
    "\n",
    "```{admonition} What is a Probability Distribution?\n",
    ":class: note, dropdown\n",
    "\n",
    "A **probability distribution** describes how values of a random variable are distributed. It tells us the likelihood of different outcomes occurring.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Discrete Probability Distribution**  \n",
    "A discrete probability distribution is used for **discrete random variables**, where the variable takes a finite or countably infinite number of values.\n",
    "\n",
    "Each possible value $ x_i $ has an associated probability $ P(X = x_i) $, and the total probability must sum to 1:\n",
    "\n",
    "$$\n",
    "\\sum_{i} P(X = x_i) = 1\n",
    "$$\n",
    "\n",
    "**Probability Mass Function (PMF):**  \n",
    "For a discrete random variable, the **probability mass function (PMF)**, denoted as $ P(X = x) $, gives the probability of the random variable taking a specific value $ x $. It satisfies:\n",
    "\n",
    "1. $ 0 \\leq P(X = x) \\leq 1 $ for all $ x $.\n",
    "2. The total probability is 1:\n",
    "\n",
    "   $$\n",
    "   \\sum_x P(X = x) = 1\n",
    "   $$\n",
    "\n",
    "**Example: Rolling a Fair Die**  \n",
    "For a fair six-sided die, the probability of each face is:\n",
    "\n",
    "$$\n",
    "P(X = x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{6}, & x = 1,2,3,4,5,6 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The sum of probabilities:\n",
    "\n",
    "$$\n",
    "\\sum_{x=1}^{6} P(X = x) = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = 1\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**2. Continuous Probability Distribution**  \n",
    "A continuous probability distribution is used for **continuous random variables**, where the variable can take any value in an interval.\n",
    "\n",
    "**Probability Density Function (PDF):**  \n",
    "Instead of a probability mass function (PMF), we use a **probability density function (PDF)**, denoted as $ f_X(x) $. The probability of the variable lying in an interval $ [a, b] $ is:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b) = \\int_a^b f_X(x) \\, dx\n",
    "$$\n",
    "\n",
    "For a valid probability density function, it must satisfy:\n",
    "\n",
    "1. $ f_X(x) \\geq 0 $ for all $ x $\n",
    "2. The total probability must integrate to 1:\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f_X(x) dx = 1\n",
    "$$\n",
    "\n",
    "**Example: Standard Normal Distribution (Gaussian)**  \n",
    "The normal distribution is a common continuous distribution:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}, \\quad -\\infty < x < \\infty\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mu $ is the mean (center of the distribution).\n",
    "- $ \\sigma^2 $ is the variance (spread of the distribution).\n",
    "\n",
    "For a **standard normal distribution** ($ \\mu = 0, \\sigma^2 = 1 $):\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n",
    "$$\n",
    "\n",
    "To find the probability of $ X $ being in a range, we integrate:\n",
    "\n",
    "$$\n",
    "P(-1 \\leq X \\leq 1) = \\int_{-1}^{1} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} dx\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key Differences Between Discrete and Continuous Distributions**  \n",
    "\n",
    "| Feature            | Discrete Distribution                 | Continuous Distribution |\n",
    "|-------------------|--------------------------------|--------------------------|\n",
    "| Random Variable Type | Takes countable values (e.g., integers) | Takes uncountable values (real numbers) |\n",
    "| Probability Function | Probability Mass Function (PMF) | Probability Density Function (PDF) |\n",
    "| Probability Calculation | $ P(X = x) $ gives exact probability | $ P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx $ |\n",
    "| Example | Rolling a die, number of heads in coin flips | Heights, weights, webpage load times |\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```{admonition} What is a Probability Density Function?\n",
    ":class: note, dropdown\n",
    "\n",
    "A **Probability Density Function (PDF)** describes the likelihood of a continuous random variable taking on a specific value. Unlike a **Probability Mass Function (PMF)** (used for discrete variables), the PDF does not give the probability of a single outcome but instead provides a function that, when integrated over an interval, gives the probability of the variable falling within that range.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "For a continuous random variable $ X $, the **probability density function (PDF)**, denoted as $ f_X(x) $, satisfies the following properties:\n",
    "\n",
    "1. **Non-negativity:**  \n",
    "\n",
    "   $$\n",
    "   f_X(x) \\geq 0, \\quad \\forall x \\in \\mathbb{R}\n",
    "   $$\n",
    "\n",
    "2. **Total Probability is 1:** \n",
    "\n",
    "   $$\n",
    "   \\int_{-\\infty}^{\\infty} f_X(x) \\, dx = 1\n",
    "   $$\n",
    "\n",
    "3. **Probability of an Interval:**  \n",
    "   The probability that $ X $ lies in an interval $ [a, b] $ is given by:\n",
    "\n",
    "   $$\n",
    "   P(a \\leq X \\leq b) = \\int_a^b f_X(x) \\, dx\n",
    "   $$\n",
    "\n",
    "Since a continuous random variable can take an infinite number of values, the probability of it taking a specific single value is always **zero**:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\int_x^x f_X(x) \\, dx = 0\n",
    "$$\n",
    "\n",
    "This is why we always consider probabilities over intervals rather than individual points.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Uniform Distribution**  \n",
    "A continuous random variable $ X $ following a **Uniform Distribution** over the interval $ [a, b] $ has a PDF:\n",
    "\n",
    "$$\n",
    "f_X(x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{b - a}, & a \\leq x \\leq b \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The probability of $ X $ being in a subinterval $ [c, d] $ (where $ a \\leq c < d \\leq b $) is:\n",
    "\n",
    "$$\n",
    "P(c \\leq X \\leq d) = \\int_c^d \\frac{1}{b - a} \\, dx = \\frac{d - c}{b - a}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Normal (Gaussian) Distribution**  \n",
    "A **Normal (Gaussian) Distribution** is given by the PDF:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}, \\quad -\\infty < x < \\infty\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mu $ is the **mean** (center of the distribution).\n",
    "- $ \\sigma^2 $ is the **variance** (spread of the distribution).\n",
    "\n",
    "To find the probability of $ X $ falling in a certain range $ [a, b] $, we compute:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b) = \\int_a^b \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} dx\n",
    "$$\n",
    "\n",
    "Since this integral **does not have a closed-form solution**, we use numerical integration or lookup tables for cumulative probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Differences Between PMF and PDF**  \n",
    "\n",
    "| Feature            | PMF (Discrete)                          | PDF (Continuous)                    |\n",
    "|-------------------|--------------------------------|--------------------------------|\n",
    "| Definition        | $ P(X = x) $ gives exact probability of a value | $ f_X(x) $ represents density, not probability |\n",
    "| Total Probability | $ \\sum P(X = x) = 1 $ | $ \\int_{-\\infty}^{\\infty} f_X(x) dx = 1 $ |\n",
    "| Single Value Probability | $ P(X = x) > 0 $ for some $ x $ | $ P(X = x) = 0 $ for all $ x $ |\n",
    "| Example          | Number of heads in 10 coin flips | Height of people in cm |\n",
    "\n",
    "```\n",
    "```{admonition} What is a Cumulative Density Function?\n",
    ":class: note, dropdown\n",
    "The **Cumulative Distribution Function (CDF)** gives the probability that a random variable $ X $ takes on a value **less than or equal to** a given number $ x $. It is useful for describing both **discrete** and **continuous** probability distributions.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "The **Cumulative Distribution Function (CDF)** of a random variable $ X $, denoted as $ F_X(x) $, is defined as:\n",
    "\n",
    "$$\n",
    "F_X(x) = P(X \\leq x)\n",
    "$$\n",
    "\n",
    "For **discrete random variables**, the CDF is the sum of probabilities up to $ x $:\n",
    "\n",
    "$$\n",
    "F_X(x) = \\sum_{t \\leq x} P(X = t)\n",
    "$$\n",
    "\n",
    "For **continuous random variables**, the CDF is obtained by integrating the probability density function (PDF):\n",
    "\n",
    "$$\n",
    "F_X(x) = \\int_{-\\infty}^{x} f_X(t) \\, dt\n",
    "$$\n",
    "\n",
    "where $ f_X(x) $ is the **Probability Density Function (PDF)**.\n",
    "\n",
    "---\n",
    "\n",
    "**Properties of the CDF**  \n",
    "1. **Non-decreasing Function:**  \n",
    "   Since probabilities accumulate, the CDF is always **non-decreasing**:\n",
    "\n",
    "   $$\n",
    "   F_X(a) \\leq F_X(b), \\quad \\text{for } a \\leq b\n",
    "   $$\n",
    "\n",
    "2. **Limits:**  \n",
    "   - The smallest possible value of $ X $ has a probability of **0**:\n",
    "\n",
    "     $$\n",
    "     \\lim_{x \\to -\\infty} F_X(x) = 0\n",
    "     $$\n",
    "\n",
    "   - The largest possible value of $ X $ has a probability of **1**:\n",
    "\n",
    "     $$\n",
    "     \\lim_{x \\to \\infty} F_X(x) = 1\n",
    "     $$\n",
    "\n",
    "3. **Computing Probability Between Two Values:**  \n",
    "   The probability that $ X $ lies in an interval $ [a, b] $ is:\n",
    "\n",
    "   $$\n",
    "   P(a \\leq X \\leq b) = F_X(b) - F_X(a)\n",
    "   $$\n",
    "\n",
    "4. **Relationship with PDF:**  \n",
    "   If $ X $ is continuous, the CDF and PDF are related by differentiation:\n",
    "\n",
    "   $$\n",
    "   f_X(x) = \\frac{d}{dx} F_X(x)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Discrete Random Variable (Rolling a Fair Die)**  \n",
    "Let $ X $ be the result of rolling a fair six-sided die. The **PMF** is:\n",
    "\n",
    "$$\n",
    "P(X = x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{6}, & x = 1,2,3,4,5,6 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The **CDF** is:\n",
    "\n",
    "$$\n",
    "F_X(x) =\n",
    "\\begin{cases}\n",
    "0, & x < 1 \\\\\n",
    "\\frac{1}{6}, & 1 \\leq x < 2 \\\\\n",
    "\\frac{2}{6}, & 2 \\leq x < 3 \\\\\n",
    "\\frac{3}{6}, & 3 \\leq x < 4 \\\\\n",
    "\\frac{4}{6}, & 4 \\leq x < 5 \\\\\n",
    "\\frac{5}{6}, & 5 \\leq x < 6 \\\\\n",
    "1, & x \\geq 6\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This means:\n",
    "- The probability of rolling **≤ 3** is $ F_X(3) = \\frac{3}{6} = 0.5 $.\n",
    "- The probability of rolling **between 2 and 4** is:\n",
    "\n",
    "  $$\n",
    "  P(2 \\leq X \\leq 4) = F_X(4) - F_X(2) = \\frac{4}{6} - \\frac{2}{6} = \\frac{2}{6}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Continuous Random Variable (Uniform Distribution on $ [0,1] $)**  \n",
    "For a uniform distribution between 0 and 1, the **PDF** is:\n",
    "\n",
    "$$\n",
    "f_X(x) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\leq x \\leq 1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The **CDF** is:\n",
    "\n",
    "$$\n",
    "F_X(x) =\n",
    "\\begin{cases}\n",
    "0, & x < 0 \\\\\n",
    "x, & 0 \\leq x \\leq 1 \\\\\n",
    "1, & x > 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "- $ P(X \\leq 0.5) = F_X(0.5) = 0.5 $\n",
    "- $ P(0.2 \\leq X \\leq 0.8) = F_X(0.8) - F_X(0.2) = 0.8 - 0.2 = 0.6 $\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Normal (Gaussian) Distribution**  \n",
    "For a **Normal (Gaussian) distribution**:\n",
    "\n",
    "$$\n",
    "F_X(x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(t - \\mu)^2}{2\\sigma^2}} dt\n",
    "$$\n",
    "\n",
    "This integral **does not have a closed-form solution**, so we use numerical approximations or lookup tables.\n",
    "\n",
    "For a **standard normal distribution** ($ \\mu = 0, \\sigma^2 = 1 $), the CDF is denoted as:\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{t^2}{2}} dt\n",
    "$$\n",
    "\n",
    "Common values (from a normal table):\n",
    "- $ \\Phi(0) = 0.5 $\n",
    "- $ \\Phi(1) \\approx 0.8413 $\n",
    "- $ \\Phi(-1) \\approx 0.1587 $\n",
    "\n",
    "To find $ P(0 \\leq X \\leq 1) $ for a standard normal variable:\n",
    "\n",
    "$$\n",
    "P(0 \\leq X \\leq 1) = \\Phi(1) - \\Phi(0) = 0.8413 - 0.5 = 0.3413\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key Differences Between PDF and CDF**  \n",
    "\n",
    "| Feature | PDF (Continuous) | CDF |\n",
    "|---------|-----------------|-----|\n",
    "| Definition | $ f_X(x) $ gives the density, not probability | $ F_X(x) = P(X \\leq x) $ gives cumulative probability |\n",
    "| Relationship | $ P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx $ | $ P(a \\leq X \\leq b) = F_X(b) - F_X(a) $ |\n",
    "| Example | $ f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} $ (Normal) | $ F_X(x) = \\int_{-\\infty}^{x} f_X(t) dt $ |\n",
    "\n",
    "```\n",
    "```{admonition} What is Expectation of a random variable?\n",
    ":class: note, dropdown\n",
    "\n",
    "The **expectation** (or **expected value**) of a random variable represents its long-term average value over many trials. It gives an idea of the **center** of the distribution.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "For a random variable $ X $, the expectation (denoted as $ \\mathbb{E}[X] $) is defined as:\n",
    "\n",
    "- **For a discrete random variable:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\sum_{i} x_i P(X = x_i)\n",
    "  $$\n",
    "\n",
    "- **For a continuous random variable:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_X(x) \\, dx\n",
    "  $$\n",
    "\n",
    "where:\n",
    "- $ P(X = x_i) $ is the probability mass function (PMF) for discrete variables.\n",
    "- $ f_X(x) $ is the probability density function (PDF) for continuous variables.\n",
    "\n",
    "The expectation can be interpreted as a **weighted average**, where each possible value of $ X $ is weighted by its probability.\n",
    "\n",
    "---\n",
    "\n",
    "**Properties of Expectation**  \n",
    "\n",
    "1. **Linearity:**  \n",
    "   For any two random variables $ X $ and $ Y $, and constants $ a, b $:\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}[aX + bY] = a\\mathbb{E}[X] + b\\mathbb{E}[Y]\n",
    "   $$\n",
    "\n",
    "2. **Expectation of a Constant:**  \n",
    "   If $ c $ is a constant, then:\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}[c] = c\n",
    "   $$\n",
    "\n",
    "3. **Expectation of a Function of X:**  \n",
    "   If $ g(X) $ is a function of a random variable $ X $, then:\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}[g(X)] = \\sum_{i} g(x_i) P(X = x_i) \\quad \\text{(discrete)}\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_X(x) \\, dx \\quad \\text{(continuous)}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Discrete Random Variable (Rolling a Fair Die)**  \n",
    "Let $ X $ be the result of rolling a fair six-sided die. The possible values are $ X = \\{1,2,3,4,5,6\\} $, and the probability of each value is:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\frac{1}{6}, \\quad x \\in \\{1,2,3,4,5,6\\}\n",
    "$$\n",
    "\n",
    "The expectation is:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum_{x=1}^{6} x P(X = x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1+2+3+4+5+6}{6} = \\frac{21}{6} = 3.5\n",
    "$$\n",
    "\n",
    "So, if you roll a fair die many times, the **average outcome** will be **3.5**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Continuous Random Variable (Uniform Distribution on [0,1])**  \n",
    "Let $ X $ follow a uniform distribution on $ [0,1] $, meaning its PDF is:\n",
    "\n",
    "$$\n",
    "f_X(x) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\leq x \\leq 1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The expectation is:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_0^1 x f_X(x) dx = \\int_0^1 x \\cdot 1 \\, dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{x^2}{2} \\Big|_0^1 = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "So, the **expected value of a uniformly distributed variable** on $ [0,1] $ is **0.5**.\n",
    "\n",
    "---\n",
    "\n",
    "**Expectation and Mean in Statistics**  \n",
    "The expectation $ \\mathbb{E}[X] $ is also called the **mean** or **first moment** of a random variable and is denoted as:\n",
    "\n",
    "$$\n",
    "\\mu = \\mathbb{E}[X]\n",
    "$$\n",
    "\n",
    "For a normal distribution $ X \\sim \\mathcal{N}(\\mu, \\sigma^2) $, the expected value is simply:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\mu\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- Expectation is a **long-run average** value of a random variable.\n",
    "- For **discrete** variables, expectation is a **sum** over all possible values.\n",
    "- For **continuous** variables, expectation is an **integral** over the probability density.\n",
    "- Expectation satisfies **linearity**, meaning sums and constants can be pulled out.\n",
    "```\n",
    "```{admonition} What is meant by Expectation over a probability distribution?\n",
    ":class: tip, dropdown\n",
    "Expectation over a probability distribution means computing the **average value** of a function of a random variable, weighted by the probability distribution of that variable.\n",
    "\n",
    "In simpler terms, if a random variable $ X $ follows a certain probability distribution, the expectation tells us the **average value of $ X $** when sampled from that distribution.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "For a function $ g(X) $ of a random variable $ X $, the expectation over a probability distribution is:\n",
    "\n",
    "- **For a discrete random variable** with probability mass function (PMF) $ P(X = x) $:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[g(X)] = \\sum_{x} g(x) P(X = x)\n",
    "  $$\n",
    "\n",
    "- **For a continuous random variable** with probability density function (PDF) $ f_X(x) $:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_X(x) \\, dx\n",
    "  $$\n",
    "\n",
    "This tells us the expected value of the function $ g(X) $ when $ X $ is sampled according to its probability distribution.\n",
    "\n",
    "---\n",
    "\n",
    "**Special Case: Expectation of $ X $ Itself**  \n",
    "If $ g(X) = X $, then the expectation simply gives the **mean** of the distribution:\n",
    "\n",
    "- **Discrete case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\sum_{x} x P(X = x)\n",
    "  $$\n",
    "\n",
    "- **Continuous case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_X(x) \\, dx\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "**Example 1: Discrete Expectation Over a Probability Distribution**  \n",
    "Consider a **biased** coin flip where $ X $ represents the number of heads in a single flip:\n",
    "\n",
    "- $ P(X = 1) = p $ (probability of heads)\n",
    "- $ P(X = 0) = 1 - p $ (probability of tails)\n",
    "\n",
    "The expectation of $ X $ is:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = (1 \\cdot p) + (0 \\cdot (1 - p)) = p\n",
    "$$\n",
    "\n",
    "This means that if we repeatedly flip the coin, the **average number of heads per flip** is equal to the probability of getting heads.\n",
    "\n",
    "---\n",
    "\n",
    "**Example 2: Continuous Expectation Over a Probability Distribution**  \n",
    "Let $ X $ follow a standard **normal distribution** $ \\mathcal{N}(0,1) $, meaning it has the PDF:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "To compute the expectation:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_X(x) dx\n",
    "$$\n",
    "\n",
    "Since the normal distribution is **symmetric around zero**, the positive and negative contributions cancel out:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = 0\n",
    "$$\n",
    "\n",
    "which makes sense because a standard normal distribution has a mean of zero.\n",
    "\n",
    "---\n",
    "\n",
    "**Expectation of a Function Over a Distribution**  \n",
    "Instead of computing $ \\mathbb{E}[X] $, we can compute the expectation of a function $ g(X) $.  \n",
    "\n",
    "For example, consider computing the expectation of $ g(X) = X^2 $ for a normal distribution:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\int_{-\\infty}^{\\infty} x^2 f_X(x) dx\n",
    "$$\n",
    "\n",
    "For a normal distribution $ X \\sim \\mathcal{N}(\\mu, \\sigma^2) $, it is a known result that:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\sigma^2 + \\mu^2\n",
    "$$\n",
    "\n",
    "which shows how variance and mean influence the expected squared value.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- Expectation over a probability distribution means computing the average outcome, weighted by the probability of each outcome.\n",
    "- It applies to both **discrete** (sums) and **continuous** (integrals) cases.\n",
    "- The expectation of a function $ g(X) $ can be computed using the probability distribution of $ X $.\n",
    "- The expectation of $ X $ itself gives the **mean** of the distribution.\n",
    "```\n",
    "```{admonition} Expectation of a Function Over a Distribution vs. Expectation Over a Probability Distribution\n",
    ":class: tip, dropdown\n",
    "**1. Expectation Over a Probability Distribution**  \n",
    "This refers to the general concept of computing an expected value based on a **probability distribution**. It can apply to a random variable $ X $ itself or to any function of $ X $.\n",
    "\n",
    "If $ X $ is a random variable with a probability distribution given by:\n",
    "- **PMF** $ P(X = x) $ (discrete case)\n",
    "- **PDF** $ f_X(x) $ (continuous case)\n",
    "\n",
    "Then the expectation of $ X $ itself is:\n",
    "\n",
    "- **Discrete Case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\sum_{x} x P(X = x)\n",
    "  $$\n",
    "  \n",
    "- **Continuous Case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_X(x) dx\n",
    "  $$\n",
    "\n",
    "This simply computes the **mean** or **average** value of $ X $ when sampled from its probability distribution.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Expectation of a Function Over a Distribution**  \n",
    "This extends the idea of expectation to **functions of a random variable**. Instead of computing the expectation of $ X $, we compute the expectation of some function **$ g(X) $**, which could be **nonlinear**.\n",
    "\n",
    "The expectation of a function $ g(X) $ over a probability distribution is:\n",
    "\n",
    "- **Discrete Case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[g(X)] = \\sum_{x} g(x) P(X = x)\n",
    "  $$\n",
    "  \n",
    "- **Continuous Case:**\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_X(x) dx\n",
    "  $$\n",
    "\n",
    "This formulation is useful when dealing with **moment calculations**, **variance computations**, and **statistical transformations**.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Difference**  \n",
    "\n",
    "| Concept | Expectation Over a Probability Distribution | Expectation of a Function Over a Distribution |\n",
    "|---------|--------------------------------|--------------------------------|\n",
    "| Definition | Computes the expectation of the random variable itself | Computes the expectation of a function of the random variable |\n",
    "| Formula (Discrete) | $ \\mathbb{E}[X] = \\sum x P(X = x) $ | $ \\mathbb{E}[g(X)] = \\sum g(x) P(X = x) $ |\n",
    "| Formula (Continuous) | $ \\mathbb{E}[X] = \\int x f_X(x) dx $ | $ \\mathbb{E}[g(X)] = \\int g(x) f_X(x) dx $ |\n",
    "| Example | Mean of a normal distribution: $ \\mathbb{E}[X] = \\mu $ | Expected squared value: $ \\mathbb{E}[X^2] = \\sigma^2 + \\mu^2 $ |\n",
    "| Purpose | Computes the **average value** of a random variable | Computes the **average value of a transformed variable** |\n",
    "\n",
    "---\n",
    "\n",
    "**Example 1: Expectation Over a Probability Distribution (Mean of a Fair Die)**  \n",
    "Let $ X $ be the result of rolling a fair six-sided die:\n",
    "\n",
    "$$\n",
    "P(X = x) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{6}, & x \\in \\{1,2,3,4,5,6\\} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The expectation (mean value) of $ X $ is:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum_{x=1}^{6} x P(X = x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{6} (1 + 2 + 3 + 4 + 5 + 6) = 3.5\n",
    "$$\n",
    "\n",
    "This means the **average outcome of rolling the die** is **3.5**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example 2: Expectation of a Function Over a Distribution (Expected Squared Value of a Fair Die)**  \n",
    "Now, let's compute the expectation of $ g(X) = X^2 $:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\sum_{x=1}^{6} x^2 P(X = x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{6} (1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{6} (1 + 4 + 9 + 16 + 25 + 36) = \\frac{91}{6} \\approx 15.17\n",
    "$$\n",
    "\n",
    "This result tells us that the **expected squared outcome** of rolling the die is **15.17**, which is **not** the same as squaring the expected value:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X]^2 = 3.5^2 = 12.25\n",
    "$$\n",
    "\n",
    "This difference is important in variance calculations:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Example 3: Expectation of a Function in a Continuous Distribution**  \n",
    "Let $ X $ follow a standard **normal distribution** $ \\mathcal{N}(0,1) $, meaning its PDF is:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "To compute the expectation of $ X^2 $:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\int_{-\\infty}^{\\infty} x^2 f_X(x) dx\n",
    "$$\n",
    "\n",
    "For a normal distribution $ X \\sim \\mathcal{N}(\\mu, \\sigma^2) $, it is a known result that:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\sigma^2 + \\mu^2\n",
    "$$\n",
    "\n",
    "For a standard normal distribution ($ \\mu = 0, \\sigma^2 = 1 $), this simplifies to:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X^2] = 1\n",
    "$$\n",
    "\n",
    "Again, this shows the difference between $ \\mathbb{E}[X] = 0 $ and $ \\mathbb{E}[X^2] = 1 $.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- **Expectation over a probability distribution** finds the average of the **random variable**.\n",
    "- **Expectation of a function over a distribution** finds the average of a **transformed random variable**.\n",
    "- If $ g(X) = X $, the expectation of the function reduces to the expectation of the variable.\n",
    "- These concepts are essential for **moments**, **variance**, and **transformations** in probability.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```{admonition} What is chain rule of probability?\n",
    ":class: note, dropdown\n",
    "The **chain rule of probability** (also called the **product rule**) allows us to compute the joint probability of multiple events by breaking it down into conditional probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "For any $ n $ random variables $ X_1, X_2, \\dots, X_n $, their joint probability can be decomposed as:\n",
    "\n",
    "$$\n",
    "P(X_1, X_2, \\dots, X_n) = P(X_1) P(X_2 \\mid X_1) P(X_3 \\mid X_1, X_2) \\dots P(X_n \\mid X_1, X_2, \\dots, X_{n-1})\n",
    "$$\n",
    "\n",
    "In general, for **two** random variables:\n",
    "\n",
    "$$\n",
    "P(A, B) = P(A \\mid B) P(B) = P(B \\mid A) P(A)\n",
    "$$\n",
    "\n",
    "For **three** random variables:\n",
    "\n",
    "$$\n",
    "P(A, B, C) = P(A) P(B \\mid A) P(C \\mid A, B)\n",
    "$$\n",
    "\n",
    "This process extends to **any number of variables**.\n",
    "\n",
    "---\n",
    "\n",
    "**Intuition**  \n",
    "The chain rule breaks down the **joint probability** into a sequence of **conditional probabilities**, explaining how each variable depends on the previous ones.\n",
    "\n",
    "Example: Suppose we have three events:\n",
    "- $ X_1 $ = \"It rains\"\n",
    "- $ X_2 $ = \"I carry an umbrella\"\n",
    "- $ X_3 $ = \"I stay dry\"\n",
    "\n",
    "Using the chain rule:\n",
    "\n",
    "$$\n",
    "P(\\text{Rain, Umbrella, Dry}) = P(\\text{Rain}) P(\\text{Umbrella} \\mid \\text{Rain}) P(\\text{Dry} \\mid \\text{Rain, Umbrella})\n",
    "$$\n",
    "\n",
    "Each probability **conditions on the previous** event, showing how they are **linked**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Probability of Drawing Cards**  \n",
    "Consider drawing **three** cards from a deck **without replacement**:\n",
    "\n",
    "- $ A $ = \"First card is an Ace\"\n",
    "- $ B $ = \"Second card is an Ace\"\n",
    "- $ C $ = \"Third card is an Ace\"\n",
    "\n",
    "The probability of drawing three Aces is:\n",
    "\n",
    "$$\n",
    "P(A, B, C) = P(A) P(B \\mid A) P(C \\mid A, B)\n",
    "$$\n",
    "\n",
    "Given there are **4 Aces in 52 cards**, we calculate:\n",
    "\n",
    "$$\n",
    "P(A) = \\frac{4}{52}\n",
    "$$\n",
    "\n",
    "If we already drew an Ace, only **3 Aces remain in 51 cards**:\n",
    "\n",
    "$$\n",
    "P(B \\mid A) = \\frac{3}{51}\n",
    "$$\n",
    "\n",
    "If two Aces are drawn, only **2 Aces remain in 50 cards**:\n",
    "\n",
    "$$\n",
    "P(C \\mid A, B) = \\frac{2}{50}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "P(A, B, C) = \\frac{4}{52} \\times \\frac{3}{51} \\times \\frac{2}{50} = \\frac{24}{132600} \\approx 0.00018\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Application in Machine Learning and Bayesian Networks**  \n",
    "The chain rule is fundamental in:\n",
    "- **Bayesian Networks**: Used to compute probabilities in graphical models.\n",
    "- **Hidden Markov Models (HMMs)**: Used for **sequence modeling**.\n",
    "- **Naive Bayes Classifier**: Assumes conditional independence to simplify computations.\n",
    "\n",
    "For a Bayesian network with **nodes $ X_1, X_2, \\dots, X_n $** structured in a **dependency graph**, the chain rule becomes:\n",
    "\n",
    "$$\n",
    "P(X_1, X_2, \\dots, X_n) = \\prod_{i=1}^{n} P(X_i \\mid \\text{Parents}(X_i))\n",
    "$$\n",
    "\n",
    "where **Parents($ X_i $)** are the nodes that influence $ X_i $.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- The **chain rule** expresses **joint probability** in terms of **conditional probabilities**.\n",
    "- It helps in **breaking down complex probability calculations**.\n",
    "- It is widely used in **Bayesian inference, machine learning, and probability theory**.\n",
    "```\n",
    "```{admonition} Definition of Joint Probability\n",
    ":class: note, dropdown\n",
    "\n",
    "The **joint probability** of two or more random variables is the probability that all events occur simultaneously.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**  \n",
    "For two random variables $ X $ and $ Y $, the **joint probability** is denoted as:\n",
    "\n",
    "$$\n",
    "P(X = x, Y = y)\n",
    "$$\n",
    "\n",
    "which represents the probability that **both** $ X = x $ and $ Y = y $ occur **together**.\n",
    "\n",
    "For **multiple variables** $ X_1, X_2, \\dots, X_n $, the joint probability is:\n",
    "\n",
    "$$\n",
    "P(X_1 = x_1, X_2 = x_2, \\dots, X_n = x_n)\n",
    "$$\n",
    "\n",
    "which represents the probability that all random variables take their respective values **at the same time**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Rolling Two Dice**  \n",
    "Let $ X $ and $ Y $ be the outcomes of rolling two fair six-sided dice.\n",
    "\n",
    "- There are **36 possible outcomes** since each die has 6 sides.\n",
    "- The probability of any specific outcome, e.g., $ (X = 2, Y = 5) $, is:\n",
    "\n",
    "  $$\n",
    "  P(X = 2, Y = 5) = \\frac{1}{36}\n",
    "  $$\n",
    "\n",
    "since each of the 36 outcomes is equally likely.\n",
    "\n",
    "---\n",
    "\n",
    "**Computing Joint Probability Using Conditional Probability**  \n",
    "Using the **chain rule**, joint probability can be computed as:\n",
    "\n",
    "$$\n",
    "P(X, Y) = P(X \\mid Y) P(Y)\n",
    "$$\n",
    "\n",
    "or equivalently:\n",
    "\n",
    "$$\n",
    "P(X, Y) = P(Y \\mid X) P(X)\n",
    "$$\n",
    "\n",
    "This expresses the joint probability in terms of **conditional probability**.\n",
    "\n",
    "---\n",
    "\n",
    "**Independent Events and Joint Probability**  \n",
    "If $ X $ and $ Y $ are **independent**, then their joint probability simplifies to:\n",
    "\n",
    "$$\n",
    "P(X, Y) = P(X) P(Y)\n",
    "$$\n",
    "\n",
    "This means that knowing $ X $ does **not** affect the probability of $ Y $.\n",
    "\n",
    "**Example: Two Independent Coin Flips**  \n",
    "Let $ X $ and $ Y $ be the outcomes of two independent coin flips, where:\n",
    "\n",
    "- $ P(X = H) = \\frac{1}{2} $\n",
    "- $ P(Y = H) = \\frac{1}{2} $\n",
    "\n",
    "Since the flips are independent:\n",
    "\n",
    "$$\n",
    "P(X = H, Y = H) = P(X = H) P(Y = H) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Joint Probability Distribution (JPD)**  \n",
    "The **joint probability distribution** describes the probability of all possible combinations of $ X $ and $ Y $.\n",
    "\n",
    "For **discrete random variables**, the JPD is represented as a **table**.\n",
    "\n",
    "| $ X \\backslash Y $ | $ Y = 0 $ | $ Y = 1 $ |\n",
    "|------------------|---------|---------|\n",
    "| $ X = 0 $ | $ P(0,0) $ | $ P(0,1) $ |\n",
    "| $ X = 1 $ | $ P(1,0) $ | $ P(1,1) $ |\n",
    "\n",
    "Each entry in the table represents a **joint probability**.\n",
    "\n",
    "For **continuous random variables**, the JPD is defined using the **joint probability density function (PDF)**:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f_{X,Y}(x, y) \\, dy \\, dx\n",
    "$$\n",
    "\n",
    "where $ f_{X,Y}(x, y) $ is the **joint PDF**.\n",
    "\n",
    "---\n",
    "\n",
    "**Marginal Probability from Joint Probability**  \n",
    "The **marginal probability** of a single variable is found by **summing** (discrete case) or **integrating** (continuous case) over the other variable.\n",
    "\n",
    "- **Discrete Case:**\n",
    "  \n",
    "  $$\n",
    "  P(X = x) = \\sum_{y} P(X = x, Y = y)\n",
    "  $$\n",
    "\n",
    "- **Continuous Case:**\n",
    "  \n",
    "  $$\n",
    "  P(X = x) = \\int_{-\\infty}^{\\infty} f_{X,Y}(x, y) \\, dy\n",
    "  $$\n",
    "\n",
    "This gives the probability of $ X $ occurring, regardless of $ Y $.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- **Joint probability** measures the probability of two or more events occurring together.\n",
    "- It can be computed using **conditional probability** and the **chain rule**.\n",
    "- **Independence** simplifies the computation as $ P(X, Y) = P(X) P(Y) $.\n",
    "- The **joint probability distribution (JPD)** describes how multiple variables interact.\n",
    "```\n",
    "```{admonition} Definition of Marginalization and Marginal Likelihood\n",
    ":class: note, dropdown\n",
    "**Marginalization** and **marginal likelihood** are related concepts in probability and Bayesian inference, both involving summing or integrating over hidden or unobserved variables. However, they serve different purposes.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Marginalization**  \n",
    "\n",
    "Marginalization refers to the process of obtaining the probability of a **subset** of random variables by summing or integrating over the remaining variables.\n",
    "\n",
    "- **For discrete random variables**, marginalization is done by summing over all possible values of another variable:\n",
    "\n",
    "  $$\n",
    "  P(X = x) = \\sum_{y} P(X = x, Y = y)\n",
    "  $$\n",
    "\n",
    "- **For continuous random variables**, marginalization is done by integrating over the unwanted variable:\n",
    "\n",
    "  $$\n",
    "  P(X = x) = \\int_{-\\infty}^{\\infty} P(X = x, Y = y) \\, dy\n",
    "  $$\n",
    "\n",
    "This process removes the dependency on the second variable, leaving only the probability distribution for the first variable.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Marginalization in a Joint Distribution**  \n",
    "\n",
    "Consider a **joint probability table** for two discrete variables $ X $ and $ Y $:\n",
    "\n",
    "| $ X \\backslash Y $ | $ Y = 0 $ | $ Y = 1 $ | Marginal $ P(X) $ |\n",
    "|------------------|---------|---------|--------------|\n",
    "| $ X = 0 $ | $ 0.2 $ | $ 0.3 $ | $ 0.2 + 0.3 = 0.5 $ |\n",
    "| $ X = 1 $ | $ 0.1 $ | $ 0.4 $ | $ 0.1 + 0.4 = 0.5 $ |\n",
    "\n",
    "The **marginal probability** of $ X = 0 $ is:\n",
    "\n",
    "$$\n",
    "P(X = 0) = P(X = 0, Y = 0) + P(X = 0, Y = 1) = 0.2 + 0.3 = 0.5\n",
    "$$\n",
    "\n",
    "This removes the dependency on $ Y $, leaving only the probabilities for $ X $.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Marginal Likelihood (Evidence in Bayesian Inference)**  \n",
    "\n",
    "The **marginal likelihood**, also called the **evidence**, is the probability of observed data, **integrating out any hidden or latent variables**.\n",
    "\n",
    "If $ X $ represents the observed data and $ Z $ is a latent (hidden) variable, the marginal likelihood is:\n",
    "\n",
    "- **For discrete variables**:\n",
    "\n",
    "  $$\n",
    "  P(X) = \\sum_{Z} P(X \\mid Z) P(Z)\n",
    "  $$\n",
    "\n",
    "- **For continuous variables**:\n",
    "\n",
    "  $$\n",
    "  P(X) = \\int P(X \\mid Z) P(Z) \\, dZ\n",
    "  $$\n",
    "\n",
    "This integral sums over all possible values of the latent variable $ Z $, making $ P(X) $ a **weighted sum of likelihoods over all possible latent variables**.\n",
    "\n",
    "---\n",
    "\n",
    "**Example: Bayesian Model Evidence**  \n",
    "\n",
    "Suppose we are classifying an email as **spam ($ S $) or not spam ($ \\neg S $)**, but we do not know the exact proportion of spam emails. Let:\n",
    "\n",
    "- $ X $ = \"email contains the word 'free'\"\n",
    "- $ S $ = \"email is spam\"\n",
    "- $ P(X \\mid S) = 0.8 $ (80% of spam emails contain \"free\")\n",
    "- $ P(X \\mid \\neg S) = 0.1 $ (only 10% of non-spam emails contain \"free\")\n",
    "- $ P(S) = 0.3 $, meaning 30% of emails are spam\n",
    "- $ P(\\neg S) = 0.7 $, meaning 70% of emails are not spam\n",
    "\n",
    "Using **the law of total probability**, the marginal likelihood of $ X $ (observing \"free\") is:\n",
    "\n",
    "$$\n",
    "P(X) = P(X \\mid S) P(S) + P(X \\mid \\neg S) P(\\neg S)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X) = (0.8 \\times 0.3) + (0.1 \\times 0.7) = 0.24 + 0.07 = 0.31\n",
    "$$\n",
    "\n",
    "This marginal likelihood helps in **Bayesian inference**, particularly in **Bayes’ theorem**:\n",
    "\n",
    "$$\n",
    "P(S \\mid X) = \\frac{P(X \\mid S) P(S)}{P(X)}\n",
    "$$\n",
    "\n",
    "which gives the probability of an email being spam given that it contains \"free.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Differences Between Marginalization and Marginal Likelihood**  \n",
    "\n",
    "| Feature | Marginalization | Marginal Likelihood |\n",
    "|---------|----------------|---------------------|\n",
    "| Definition | Computes the probability of a subset of variables by summing or integrating over the others | Computes the probability of observed data by integrating out hidden variables |\n",
    "| Purpose | To remove dependencies on other variables and find marginal probabilities | Used in **Bayesian inference** to compute the evidence for a model |\n",
    "| Formula (Discrete) | $ P(X) = \\sum_{Y} P(X, Y) $ | $ P(X) = \\sum_{Z} P(X \\mid Z) P(Z) $ |\n",
    "| Formula (Continuous) | $ P(X) = \\int P(X, Y) dy $ | $ P(X) = \\int P(X \\mid Z) P(Z) dZ $ |\n",
    "| Application | Used in probability theory, graphical models | Used in Bayesian statistics and machine learning |\n",
    "| Example | Summing over joint probabilities to get $ P(X) $ | Computing $ P(X) $ by integrating over a latent variable $ Z $ |\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- **Marginalization** computes the probability of a variable by removing dependencies on other variables.\n",
    "- **Marginal probability** is found by summing (discrete case) or integrating (continuous case) over the other variables.\n",
    "- **Marginal likelihood (evidence)** is used in **Bayesian inference** to find the probability of observed data **regardless of hidden variables**.\n",
    "- These concepts are widely used in **probabilistic graphical models, Bayesian networks, and machine learning**.\n",
    "\n",
    "```\n",
    "```{admonition} What is reparametrization trick and why is it important?\n",
    ":class: note, dropdown\n",
    "\n",
    "The **reparametrization trick** is a technique used in **variational inference**, particularly in **variational autoencoders (VAEs)**, to enable gradient-based optimization of stochastic objectives. It allows gradients to pass through **random sampling operations**, making it possible to optimize models using **backpropagation**.\n",
    "\n",
    "---\n",
    "\n",
    "**1. The Problem: Why Do We Need the Reparametrization Trick?**  \n",
    "\n",
    "In **stochastic neural networks**, we often need to optimize a loss function that involves **sampling from a probability distribution**. A common scenario is optimizing the **expected value** of a function:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)]\n",
    "$$\n",
    "\n",
    "This notation represents the **expectation of a function over a probability distribution**. It means that we are computing the expectation of the function $ f(z) $ with respect to the probability distribution $ q(z \\mid x) $.\n",
    "\n",
    "- **Expectation Over a Probability Distribution:**  \n",
    "  The expectation is taken **over the distribution** $ q(z \\mid x) $, meaning that we are integrating over all possible values of $ z $ weighted by their probability under $ q(z \\mid x) $:\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)] = \\int f(z) q(z \\mid x) dz\n",
    "  $$\n",
    "\n",
    "- **Expectation of a Function Over the Distribution:**  \n",
    "  Here, $ f(z) $ is a function of $ z $, and we want to compute its average value under the probability distribution $ q(z \\mid x) $. Since $ q(z \\mid x) $ is typically a **latent variable distribution**, we cannot compute this expectation in closed form and instead rely on **Monte Carlo sampling**.\n",
    "\n",
    "However, **direct sampling from $ q(z \\mid x) $ prevents backpropagation**, since gradients cannot flow through the sampling operation. This makes it difficult to train models that involve such expectations.\n",
    "\n",
    "---\n",
    "\n",
    "**2. The Reparametrization Trick: A Solution**  \n",
    "\n",
    "The reparametrization trick **re-writes the sampling process** in a way that allows gradients to be computed. Instead of directly sampling $ z \\sim q(z \\mid x) $, we express $ z $ as a **deterministic function** of some random noise $ \\epsilon $ and parameters $ \\mu, \\sigma $:\n",
    "\n",
    "$$\n",
    "z = \\mu + \\sigma \\cdot \\epsilon, \\quad \\text{where} \\quad \\epsilon \\sim \\mathcal{N}(0,1)\n",
    "$$\n",
    "\n",
    "This trick **separates** the randomness (introduced by $ \\epsilon $) from the learnable parameters ($ \\mu, \\sigma $), allowing **gradients to flow through $ \\mu $ and $ \\sigma $**.\n",
    "\n",
    "Now, instead of optimizing:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)]\n",
    "$$\n",
    "\n",
    "we optimize:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0,1)} [f(\\mu + \\sigma \\epsilon)]\n",
    "$$\n",
    "\n",
    "which can be **differentiated w.r.t.** $ \\mu $ and $ \\sigma $ using standard **gradient-based methods**.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Example: Variational Autoencoder (VAE)**  \n",
    "\n",
    "A **Variational Autoencoder (VAE)** uses the reparametrization trick to learn a probabilistic latent representation.\n",
    "\n",
    "1. Instead of sampling directly from $ q(z \\mid x) \\sim \\mathcal{N}(\\mu, \\sigma^2) $, we sample from a standard normal distribution:\n",
    "\n",
    "   $$\n",
    "   \\epsilon \\sim \\mathcal{N}(0,1)\n",
    "   $$\n",
    "\n",
    "2. We then reparametrize:\n",
    "\n",
    "   $$\n",
    "   z = \\mu + \\sigma \\cdot \\epsilon\n",
    "   $$\n",
    "\n",
    "3. The loss function includes a **KL-divergence term** and a **reconstruction loss**, both of which require differentiability.\n",
    "\n",
    "4. The reparametrization trick allows **gradient updates to propagate through $ \\mu $ and $ \\sigma $**.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Why Is the Reparametrization Trick Important?**  \n",
    "\n",
    "✔ **Enables Backpropagation Through Stochastic Nodes**  \n",
    "   - Without this trick, gradients cannot flow through sampling operations.  \n",
    "   - It enables training probabilistic models like VAEs using **gradient descent**.\n",
    "\n",
    "✔ **Reduces Variance in Gradient Estimates**  \n",
    "   - Compared to Monte Carlo estimation methods, it provides more stable and lower-variance gradients.\n",
    "\n",
    "✔ **Used in Bayesian Deep Learning and Reinforcement Learning**  \n",
    "   - Essential for **Bayesian neural networks**, which learn uncertainty in deep learning.\n",
    "   - Applied in **policy gradients** in reinforcement learning.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Limitations and Extensions**  \n",
    "\n",
    "- **Does not work for discrete random variables**  \n",
    "  - Alternative methods like the **Gumbel-Softmax trick** are used for discrete distributions.\n",
    "\n",
    "- **Assumes reparametrizable distributions**  \n",
    "  - The trick works well for distributions like **Gaussian**, but for more complex distributions, alternative methods (e.g., normalizing flows) are needed.\n",
    "\n",
    "---\n",
    "\n",
    "**6. Understanding the Expectation in the Given Equation**  \n",
    "\n",
    "The expectation in:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)]\n",
    "$$\n",
    "\n",
    "- **Expectation Over a Probability Distribution:**  \n",
    "  The expectation is taken over the **latent variable distribution** $ q(z \\mid x) $, meaning that we integrate over all possible values of $ z $ weighted by their probability under $ q(z \\mid x) $.\n",
    "\n",
    "  $$\n",
    "  \\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)] = \\int f(z) q(z \\mid x) dz\n",
    "  $$\n",
    "\n",
    "- **Expectation of a Function Over the Distribution:**  \n",
    "  The function $ f(z) $ could represent an objective function or loss that we are optimizing. Since $ q(z \\mid x) $ is typically **complex and unknown**, we use **Monte Carlo estimation** to approximate this expectation:\n",
    "\n",
    "  $$\n",
    "  \\frac{1}{N} \\sum_{i=1}^{N} f(z_i), \\quad z_i \\sim q(z \\mid x)\n",
    "  $$\n",
    "\n",
    "  However, **direct sampling blocks gradient flow**, which is why the **reparametrization trick** is crucial.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**  \n",
    "- **Reparametrization Trick** allows **gradient-based learning** in models that involve **stochastic sampling**.  \n",
    "- Converts sampling into a **deterministic function** of noise and parameters.  \n",
    "- Used in **VAEs**, **Bayesian deep learning**, and **reinforcement learning**.  \n",
    "- **Essential for optimizing probabilistic models using backpropagation**.  \n",
    "- The expectation in $ \\mathbb{E}_{z \\sim q(z \\mid x)} [f(z)] $ is over the **distribution** $ q(z \\mid x) $, meaning we integrate over all possible values of $ z $ to compute the expected value of $ f(z) $.\n",
    "\n",
    "```\n",
    "```{admonition} What is meant by log likelihood? Why do we maximize in neural network training?\n",
    ":class: note, dropdown\n",
    "\n",
    "**1. What is Log Likelihood?**  \n",
    "\n",
    "The **log likelihood** is a fundamental concept in probability and machine learning, used to estimate model parameters by **maximizing the probability of observed data**. It is commonly applied in **maximum likelihood estimation (MLE)** and is the foundation of many loss functions in deep learning.\n",
    "\n",
    "**Likelihood Function**  \n",
    "Given a dataset $ \\mathcal{D} = \\{ x_1, x_2, \\dots, x_n \\} $, where each $ x_i $ is a data point, and a probabilistic model with parameters $ \\theta $, the **likelihood function** is defined as:\n",
    "\n",
    "$$\n",
    "L(\\theta) = P(\\mathcal{D} \\mid \\theta)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $ P(\\mathcal{D} \\mid \\theta) $ represents the probability of observing the data $ \\mathcal{D} $ given the model parameters $ \\theta $.\n",
    "- The goal of **maximum likelihood estimation (MLE)** is to find the parameters $ \\theta^* $ that maximize this probability:\n",
    "\n",
    "  $$\n",
    "  \\theta^* = \\arg\\max_{\\theta} L(\\theta)\n",
    "  $$\n",
    "\n",
    "Since models often assume **independent** data points, the likelihood function is expressed as a product:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{n} P(x_i \\mid \\theta)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ P(x_i \\mid \\theta) $ is the probability of the individual data point $ x_i $ under the model.\n",
    "- The product arises because we assume that each data point is **independent and identically distributed (i.i.d.)**.\n",
    "\n",
    "**Log Likelihood Function**  \n",
    "The log likelihood is simply the **logarithm** of the likelihood function:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\log P(\\mathcal{D} \\mid \\theta)\n",
    "$$\n",
    "\n",
    "Using the i.i.d. assumption:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\log \\prod_{i=1}^{n} P(x_i \\mid \\theta)\n",
    "$$\n",
    "\n",
    "Applying the **logarithm property** ($ \\log ab = \\log a + \\log b $):\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{n} \\log P(x_i \\mid \\theta)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- The **logarithm transforms the product into a sum**, which is easier to compute and numerically more stable.\n",
    "- Instead of multiplying many small probabilities (which can cause numerical underflow), we sum their log probabilities.\n",
    "\n",
    "Thus, **maximizing likelihood is equivalent to maximizing the log likelihood**, which simplifies optimization.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Why Do We Maximize Log Likelihood in Neural Networks?**  \n",
    "\n",
    "Neural networks often predict probabilities. To train a model, we want to maximize the probability assigned to the correct data points, i.e., maximize:\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} \\mid \\theta)\n",
    "$$\n",
    "\n",
    "Since working with probabilities directly can be unstable (due to small values), we use the log likelihood:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\max_{\\theta} \\log L(\\theta) = \\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log P(x_i \\mid \\theta)\n",
    "$$\n",
    "\n",
    "This is the objective function used in probabilistic models.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Example: Log Likelihood in Classification (Softmax + Cross-Entropy Loss)**  \n",
    "\n",
    "In **neural network classification**, we model the probability of each class using the **softmax function**:\n",
    "\n",
    "$$\n",
    "P(y \\mid x, \\theta) = \\frac{\\exp(f_{\\theta}(x)_y)}{\\sum_{j} \\exp(f_{\\theta}(x)_j)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ f_{\\theta}(x)_y $ is the predicted score for class $ y $.\n",
    "- The denominator ensures all class probabilities sum to **1**.\n",
    "\n",
    "The likelihood for a dataset $ \\mathcal{D} $ is:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{n} P(y_i \\mid x_i, \\theta)\n",
    "$$\n",
    "\n",
    "Taking the **log likelihood**:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{n} \\log P(y_i \\mid x_i, \\theta)\n",
    "$$\n",
    "\n",
    "which is **equivalent to minimizing the cross-entropy loss**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = - \\sum_{i=1}^{n} \\log P(y_i \\mid x_i, \\theta)\n",
    "$$\n",
    "\n",
    "Thus, **maximizing log likelihood is the same as minimizing cross-entropy loss** in classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Why Log Likelihood is Used in Training?**  \n",
    "\n",
    "✔ **Converts Products into Sums**  \n",
    "   - Probabilities are small values between **0 and 1**.\n",
    "   - Multiplying many probabilities leads to **numerical underflow**.\n",
    "   - Taking the **log** prevents this issue by converting the product into a sum.\n",
    "\n",
    "✔ **Easier Optimization**  \n",
    "   - Log likelihood often results in **convex** loss functions, making gradient-based optimization more effective.\n",
    "\n",
    "✔ **Directly Related to Cross-Entropy Loss**  \n",
    "   - In classification, **maximizing log likelihood = minimizing cross-entropy loss**.\n",
    "\n",
    "✔ **Has a Probabilistic Interpretation**  \n",
    "   - Maximizing log likelihood ensures our model assigns **high probability to observed data**, leading to better generalization.\n",
    "\n",
    "✔ **Log Likelihood Gradient Helps in Backpropagation**  \n",
    "   - The gradients of log likelihood are well-defined, ensuring smooth updates in gradient descent.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Key Takeaways**  \n",
    "\n",
    "- **Log likelihood** is the logarithm of the likelihood function, used to estimate parameters in probabilistic models.  \n",
    "- **Maximizing log likelihood** finds the best parameters that make the observed data most probable.  \n",
    "- **In neural networks**, log likelihood optimization is equivalent to minimizing **cross-entropy loss** for classification.  \n",
    "- **Computationally stable** and helps avoid underflow in probability calculations.  \n",
    "- **Essential in probabilistic deep learning models**, such as **VAEs, Bayesian neural networks, and language models**.\n",
    "\n",
    "```\n",
    "```{admonition} What is KL Divergence and why is it important?\n",
    ":class: note, dropdown\n",
    "\n",
    "**1. What is KL Divergence?**  \n",
    "\n",
    "**Kullback-Leibler (KL) Divergence** is a fundamental concept in probability theory and machine learning. It measures how one probability distribution differs from another. In other words, it quantifies the **information loss** when we approximate a true distribution with another.\n",
    "\n",
    "For two probability distributions:\n",
    "- **True distribution**: $ P(x) $\n",
    "- **Approximate distribution**: $ Q(x) $\n",
    "\n",
    "The **KL divergence** is defined as:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_{x} P(x) \\log \\frac{P(x)}{Q(x)} \\quad \\text{(discrete case)}\n",
    "$$\n",
    "\n",
    "or, for continuous distributions:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\int P(x) \\log \\frac{P(x)}{Q(x)} \\, dx\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ P(x) $ is the **true** distribution (e.g., the actual data distribution).\n",
    "- $ Q(x) $ is the **approximate** distribution (e.g., a model trying to approximate $ P $).\n",
    "- The **log ratio** measures how much $ P(x) $ and $ Q(x) $ diverge at each point.\n",
    "\n",
    "The **KL divergence is always non-negative**:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) \\geq 0\n",
    "$$\n",
    "\n",
    "with equality ($ D_{\\text{KL}}(P \\parallel Q) = 0 $) if and only if **$ P(x) = Q(x) $ for all $ x $**.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Intuition Behind KL Divergence**  \n",
    "\n",
    "✔ **Measures Information Loss**  \n",
    "   - If we use $ Q(x) $ to approximate $ P(x) $, KL divergence tells us **how much information is lost**.\n",
    "\n",
    "✔ **Asymmetry: $ D_{\\text{KL}}(P \\parallel Q) \\neq D_{\\text{KL}}(Q \\parallel P) $**  \n",
    "   - KL divergence is **not symmetric**, meaning it is **not a true distance metric**.\n",
    "\n",
    "✔ **Expectation of Log Difference**  \n",
    "   - The term $ \\log \\frac{P(x)}{Q(x)} $ represents the log difference between the two distributions.\n",
    "   - KL divergence takes the **expectation under $ P(x) $**, meaning that the true distribution **weights the difference**.\n",
    "\n",
    "✔ **Lower KL = Better Approximation**  \n",
    "   - If $ D_{\\text{KL}}(P \\parallel Q) $ is small, $ Q(x) $ is a good approximation of $ P(x) $.\n",
    "   - If KL is large, $ Q(x) $ is far from $ P(x) $, meaning a poor approximation.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Why is KL Divergence Important?**  \n",
    "\n",
    "KL divergence is widely used in **machine learning, statistics, and deep learning** for **probability estimation, model optimization, and generative modeling**.\n",
    "\n",
    "✔ **Used in Variational Inference**  \n",
    "   - In **variational autoencoders (VAEs)**, KL divergence is used to **regularize** the latent space by forcing the approximate posterior $ Q(z \\mid x) $ to be close to a prior $ P(z) $.\n",
    "\n",
    "✔ **Used in Bayesian Deep Learning**  \n",
    "   - KL divergence measures how much information is lost when using an **approximate posterior** instead of the **true Bayesian posterior**.\n",
    "\n",
    "✔ **Used in Reinforcement Learning (RL)**  \n",
    "   - In **policy optimization**, KL divergence ensures that updates do not drastically change the policy distribution.\n",
    "\n",
    "✔ **Related to Cross-Entropy Loss**  \n",
    "   - Cross-entropy loss in classification problems is directly related to KL divergence.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Example: KL Divergence Between Two Normal Distributions**  \n",
    "\n",
    "For two Gaussian distributions:\n",
    "\n",
    "- **True distribution**: $ P(x) = \\mathcal{N}(\\mu_1, \\sigma_1^2) $\n",
    "- **Approximate distribution**: $ Q(x) = \\mathcal{N}(\\mu_2, \\sigma_2^2) $\n",
    "\n",
    "The KL divergence is:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) =\n",
    "\\log \\frac{\\sigma_2}{\\sigma_1} +\n",
    "\\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- The **first term** measures the difference in **variance**.\n",
    "- The **second term** measures the difference in **mean**.\n",
    "- If $ \\mu_1 = \\mu_2 $ and $ \\sigma_1 = \\sigma_2 $, then $ D_{\\text{KL}}(P \\parallel Q) = 0 $.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Symmetric Alternative: Jensen-Shannon (JS) Divergence**  \n",
    "\n",
    "Since KL divergence is **not symmetric**, an alternative is **Jensen-Shannon divergence (JS divergence)**:\n",
    "\n",
    "$$\n",
    "D_{\\text{JS}}(P \\parallel Q) = \\frac{1}{2} D_{\\text{KL}}(P \\parallel M) + \\frac{1}{2} D_{\\text{KL}}(Q \\parallel M)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "M(x) = \\frac{1}{2} (P(x) + Q(x))\n",
    "$$\n",
    "\n",
    "JS divergence **is symmetric** and **bounded between 0 and 1**, making it useful for comparing distributions.\n",
    "\n",
    "---\n",
    "\n",
    "**6. Key Takeaways**  \n",
    "\n",
    "✔ **KL divergence measures the difference between two probability distributions.**  \n",
    "✔ **It quantifies how much information is lost when using $ Q(x) $ instead of $ P(x) $.**  \n",
    "✔ **Lower KL means a better approximation.**  \n",
    "✔ **Used in VAEs, Bayesian deep learning, RL, and probability models.**  \n",
    "✔ **Not symmetric: $ D_{\\text{KL}}(P \\parallel Q) \\neq D_{\\text{KL}}(Q \\parallel P) $.**  \n",
    "✔ **JS divergence is a symmetric alternative.**\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "732d8975-53f7-4f52-8ff6-d789a8d6b24d",
   "metadata": {},
   "source": [
    "## Forward Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9b7c3-d2a5-41a7-9fb1-5c1eef5a3bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
